- [ ] support q8 quantization
  - [ ] zero copy q8 quantization with the zero-copy crate
  - [ ] have a test with https://huggingface.co/TheBloke/TinyLlama-1.1B-python-v0.1-GGUF/blob/main/tinyllama-1.1b-python-v0.1.Q8_0.gguf
- [ ] take the tensor & device framework
- [ ] wgpu tensor support